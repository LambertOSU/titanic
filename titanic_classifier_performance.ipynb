{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Performance.\n",
    "\n",
    "The purpose of this notebook is to study the performance of various classification algorithms on a particluar data set. It is divided into four sections. \n",
    "\n",
    "- [Data Prep](#data_prep): Load the data into pandas DataFrame and extract/construct features.\n",
    "\n",
    "At this point all models run with the default parameters.  This will be upgraded very soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "import xgboost\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data_prep\"></a>\n",
    "\n",
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.csv  train.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls ./input/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./input/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "Here we map representative numerical values on to non-numerical data or calculate relevant metrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sex\n",
    "sex_mapping = {\"female\": 245 ,\"male\": 143}\n",
    "data['Sex'] = data['Sex'].map(sex_mapping)\n",
    "\n",
    "\n",
    "## embarked\n",
    "embarked_mapping = {'Q' : 1, 'S' : 2, 'C' : 3}\n",
    "data['Embarked'] = data['Embarked'].fillna('S')\n",
    "data['Embarked'] = data['Embarked'].map(embarked_mapping)\n",
    "\n",
    "## cabin\n",
    "data[\"Cabin\"] = data[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "\n",
    "\n",
    "## age binning\n",
    "data['Age'].fillna((data['Age'].mean()), inplace=True)\n",
    "age_bins = [(data['Age'].min()-1), 15, 30, 45, 60, (data['Age'].max()+1)]\n",
    "age_labels =[1, 2, 3, 4, 5]\n",
    "data['Age'] = pd.cut(data['Age'], age_bins, labels=age_labels)\n",
    "\n",
    "## fare_binning\n",
    "data['Fare'].fillna((data['Fare'].median()), inplace=True)\n",
    "fare_bins = [(data['Fare'].min()-1), 5, 10, 15, 20, 30, 50, 100, (data['Fare'].max()+1)]\n",
    "fare_labels = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "data['Fare'] = pd.cut(data['Fare'],fare_bins,labels=fare_labels)\n",
    "\n",
    "## name features\n",
    "data['name_length'] = data['Name'].apply(len)\n",
    "\n",
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "# Create a new feature Title, containing the titles of passenger names\n",
    "\n",
    "data['Title'] = data['Name'].apply(get_title)\n",
    "# Group all non-common titles into one single grouping \"Rare\"\n",
    "\n",
    "data['Title'] = data['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "data['Title'] = data['Title'].replace('Mlle', 'Miss')\n",
    "data['Title'] = data['Title'].replace('Ms', 'Miss')\n",
    "data['Title'] = data['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "# Mapping titles\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "data['Title'] = data['Title'].map(title_mapping)\n",
    "data['Title'] = data['Title'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.drop(['Name', 'Ticket', 'PassengerId'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Sampling Sweep\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = 'Survived'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "        'NB' : GaussianNB(),\n",
    "        'LR' : LogisticRegression(),\n",
    "        'PC' : Perceptron(),\n",
    "        'SGD' : SGDClassifier(),\n",
    "        'SVC' : SVC(),\n",
    "        'LSVC' : LinearSVC(),\n",
    "        'KNN' : KNeighborsClassifier(),\n",
    "        'DT' : DecisionTreeClassifier(),\n",
    "        'RF' : RandomForestClassifier(),\n",
    "        'ET' : ExtraTreesClassifier(),\n",
    "        'ABC' : AdaBoostClassifier(),\n",
    "        'GBC' : GradientBoostingClassifier(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Map of model names for formatting later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names =  ['Naive Bayes',\n",
    "          'Logistic Regression',\n",
    "          'Perceptron',\n",
    "          'Stochastic Gradient Descent',\n",
    "          'Support Vector Clasifier', \n",
    "          'Linear SVC',\n",
    "          'k-Nearest Neighbors',               \n",
    "          'Decision Tree', \n",
    "          'Random Forest',\n",
    "          'Extra Trees',\n",
    "          'Adaptive Boost Classifier',\n",
    "          'Gradient Boosting Classifier']\n",
    "\n",
    "keys = [ i for i in models.keys()]\n",
    "\n",
    "model_map = dict(zip(keys,names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the test fractions, i.e. the fraction of data set aside for testing.  The balance will be used for training.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_fraction = [0.1, 0.2, 0.3, 0.4, 0.5, 0.7, 0.9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the DataFrame to store accuracy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = pd.DataFrame(keys, columns = ['Model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through test fractions splitting data accordingly.  Then loop through each model, train, test, and report accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in test_fraction:\n",
    "    \n",
    "    train, test = train_test_split(data, test_size = x)\n",
    "\n",
    "    x_train = train.drop(target,axis=1)\n",
    "    y_train = train[target]\n",
    "    x_test = test.drop(target,axis=1)\n",
    "    y_test = test[target]\n",
    "\n",
    "    for key in keys:\n",
    "\n",
    "        models[key].fit(x_train, y_train)\n",
    "        y_pred = models[key].predict(x_test)\n",
    "        accuracy.loc[accuracy.Model == key, str(x)] = round(accuracy_score(y_pred, y_test) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map model names onto abbreviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy['Model'] = accuracy['Model'].map(model_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>85.56</td>\n",
       "      <td>81.01</td>\n",
       "      <td>74.63</td>\n",
       "      <td>78.71</td>\n",
       "      <td>77.13</td>\n",
       "      <td>78.04</td>\n",
       "      <td>77.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>85.56</td>\n",
       "      <td>84.36</td>\n",
       "      <td>81.34</td>\n",
       "      <td>80.39</td>\n",
       "      <td>80.27</td>\n",
       "      <td>80.93</td>\n",
       "      <td>78.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>81.11</td>\n",
       "      <td>59.22</td>\n",
       "      <td>38.43</td>\n",
       "      <td>63.31</td>\n",
       "      <td>48.43</td>\n",
       "      <td>61.86</td>\n",
       "      <td>37.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stochastic Gradient Descent</td>\n",
       "      <td>35.56</td>\n",
       "      <td>40.78</td>\n",
       "      <td>61.57</td>\n",
       "      <td>35.85</td>\n",
       "      <td>58.52</td>\n",
       "      <td>38.14</td>\n",
       "      <td>62.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Clasifier</td>\n",
       "      <td>84.44</td>\n",
       "      <td>83.80</td>\n",
       "      <td>81.72</td>\n",
       "      <td>81.51</td>\n",
       "      <td>78.25</td>\n",
       "      <td>79.65</td>\n",
       "      <td>72.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>66.67</td>\n",
       "      <td>59.22</td>\n",
       "      <td>70.15</td>\n",
       "      <td>74.23</td>\n",
       "      <td>74.89</td>\n",
       "      <td>80.13</td>\n",
       "      <td>77.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>k-Nearest Neighbors</td>\n",
       "      <td>83.33</td>\n",
       "      <td>82.68</td>\n",
       "      <td>79.10</td>\n",
       "      <td>80.39</td>\n",
       "      <td>78.92</td>\n",
       "      <td>79.33</td>\n",
       "      <td>75.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>84.44</td>\n",
       "      <td>78.77</td>\n",
       "      <td>80.22</td>\n",
       "      <td>78.43</td>\n",
       "      <td>76.91</td>\n",
       "      <td>70.83</td>\n",
       "      <td>70.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>84.44</td>\n",
       "      <td>81.01</td>\n",
       "      <td>81.72</td>\n",
       "      <td>81.79</td>\n",
       "      <td>79.15</td>\n",
       "      <td>74.84</td>\n",
       "      <td>79.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Extra Trees</td>\n",
       "      <td>88.89</td>\n",
       "      <td>83.24</td>\n",
       "      <td>80.22</td>\n",
       "      <td>82.07</td>\n",
       "      <td>78.92</td>\n",
       "      <td>78.37</td>\n",
       "      <td>76.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Adaptive Boost Classifier</td>\n",
       "      <td>88.89</td>\n",
       "      <td>87.71</td>\n",
       "      <td>81.34</td>\n",
       "      <td>80.11</td>\n",
       "      <td>82.06</td>\n",
       "      <td>77.72</td>\n",
       "      <td>75.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>87.78</td>\n",
       "      <td>85.47</td>\n",
       "      <td>80.60</td>\n",
       "      <td>81.23</td>\n",
       "      <td>82.74</td>\n",
       "      <td>82.05</td>\n",
       "      <td>76.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Model    0.1    0.2    0.3    0.4    0.5    0.7  \\\n",
       "0                    Naive Bayes  85.56  81.01  74.63  78.71  77.13  78.04   \n",
       "1            Logistic Regression  85.56  84.36  81.34  80.39  80.27  80.93   \n",
       "2                     Perceptron  81.11  59.22  38.43  63.31  48.43  61.86   \n",
       "3    Stochastic Gradient Descent  35.56  40.78  61.57  35.85  58.52  38.14   \n",
       "4       Support Vector Clasifier  84.44  83.80  81.72  81.51  78.25  79.65   \n",
       "5                     Linear SVC  66.67  59.22  70.15  74.23  74.89  80.13   \n",
       "6            k-Nearest Neighbors  83.33  82.68  79.10  80.39  78.92  79.33   \n",
       "7                  Decision Tree  84.44  78.77  80.22  78.43  76.91  70.83   \n",
       "8                  Random Forest  84.44  81.01  81.72  81.79  79.15  74.84   \n",
       "9                    Extra Trees  88.89  83.24  80.22  82.07  78.92  78.37   \n",
       "10     Adaptive Boost Classifier  88.89  87.71  81.34  80.11  82.06  77.72   \n",
       "11  Gradient Boosting Classifier  87.78  85.47  80.60  81.23  82.74  82.05   \n",
       "\n",
       "      0.9  \n",
       "0   77.93  \n",
       "1   78.93  \n",
       "2   37.91  \n",
       "3   62.84  \n",
       "4   72.07  \n",
       "5   77.68  \n",
       "6   75.06  \n",
       "7   70.57  \n",
       "8   79.80  \n",
       "9   76.81  \n",
       "10  75.56  \n",
       "11  76.31  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Fold Validation Test\n",
    "\n",
    "We will run a k-Fold validation test on the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf_data = pd.DataFrame(keys, columns = ['Model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 10\n",
    "\n",
    "\n",
    "# make the folds to go with the keys\n",
    "kf = KFold(n_splits=num_folds)\n",
    "\n",
    "# intialize list of indices for folds\n",
    "train_idx = []\n",
    "test_idx = []\n",
    "\n",
    "# get indices for folds\n",
    "for train, test in kf.split(data):\n",
    "    train_idx.append(train)\n",
    "    test_idx.append(test)\n",
    "\n",
    "\n",
    "for n in range(len(train_idx)):    \n",
    "    \n",
    "    # loop through the first level models, fit, and test.\n",
    "    for key in keys:\n",
    "\n",
    "        x_train = data.iloc[train_idx[n]].drop([target],axis=1)\n",
    "        y_train = data.iloc[train_idx[n]].Survived\n",
    "        \n",
    "        x_test = data.iloc[test_idx[n]].drop([target],axis=1)\n",
    "        y_test = data.iloc[test_idx[n]].Survived\n",
    "        \n",
    "        models[key].fit(x_train, y_train)\n",
    "        \n",
    "        y_pred = models[key].predict(x_test)\n",
    "        \n",
    "        kf_data.loc[kf_data.Model == key, str(n)] = round(accuracy_score(y_pred, y_test) * 100, 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map names onto model keys and do some statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## names\n",
    "kf_data['Model'] = kf_data['Model'].map(model_map)\n",
    "\n",
    "## compute the stats\n",
    "kf_data['mean'] = kf_data.mean(axis=1)\n",
    "kf_data['median'] = kf_data.loc[:, kf_data.columns != 'mean'].median(axis=1)\n",
    "kf_data['std_dev'] = kf_data.loc[:, ((kf_data.columns != 'mean') \n",
    "                                     & (kf_data.columns != 'median'))].std(axis=1)\n",
    "\n",
    "## display \n",
    "kf_data[['Model', 'mean', 'median', 'std_dev']].sort_values(by = ['mean'], ascending=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id=\"blending\"></a>\n",
    "# Blending\n",
    "\n",
    "This is my first attempt at blending.  I studied [Anisotropic](https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python) and [MLWave](https://mlwave.com/kaggle-ensembling-guide/).\n",
    "\n",
    "First we'll move 20% of the data to a final validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_data, working_data = train_test_split(data, test_size = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(data.shape[0], n_splits= 9, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict of model instances\n",
    "first_level_models = {\n",
    "        'NB' : GaussianNB(),\n",
    "        'LR' : LogisticRegression(),\n",
    "        'SVC' : SVC(),\n",
    "        'KNN' : KNeighborsClassifier(),\n",
    "        'DT' : DecisionTreeClassifier(),\n",
    "        'RF' : RandomForestClassifier(),\n",
    "        'ET' : ExtraTreesClassifier(),\n",
    "        'ABC' : AdaBoostClassifier(),\n",
    "        'GBC' :  GradientBoostingClassifier(),\n",
    "        }\n",
    "\n",
    "# get the keys\n",
    "first_level_keys = [ i for i in first_level_models.keys()]\n",
    "\n",
    "# make the folds to go with the keys\n",
    "kf = KFold(n_splits=len(first_level_keys))\n",
    "\n",
    "# intialize list of indices for folds\n",
    "train_idx = []\n",
    "test_idx = []\n",
    "\n",
    "# get indices for folds\n",
    "for train, test in kf.split(working_data):\n",
    "    train_idx.append(train)\n",
    "    test_idx.append(test)\n",
    "\n",
    "# intialize counter\n",
    "n=0\n",
    "\n",
    "# train each first level model on a different fold\n",
    "for key in first_level_keys:\n",
    "    \n",
    "    x_train = data.iloc[train_idx[n]].drop([target],axis=1)\n",
    "    y_train = data.iloc[train_idx[n]].Survived\n",
    "    \n",
    "    x_test = data.iloc[test_idx[n]].drop([target],axis=1)\n",
    "    y_test = data.iloc[test_idx[n]].Survived\n",
    "    \n",
    "    first_level_models[key].fit(x_train, y_train)\n",
    "    y_pred = first_level_models[key].predict(x_test)\n",
    "    \n",
    "    print(key,' : ',round(accuracy_score(y_pred, y_test)*100, 2))\n",
    "    \n",
    "    n += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Level\n",
    "\n",
    "Go back to full working_data set for second level. All of this data has been seen by at least one classifier, which is why we set another 20% aside for final validation.  At this point, we're going to recombine the data and split it into two equal fractions.  One fraction will be used to generate the first level predictions which are used to train the second level model.  The other fraction will be used to generate the input to the second level model for testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split full data set\n",
    "train, test = train_test_split(working_data, test_size = 0.1)\n",
    "\n",
    "x_train = train.drop(target,axis=1)\n",
    "y_train = train[target]\n",
    "\n",
    "x_test = test.drop(target,axis=1)\n",
    "y_test = test[target]\n",
    "\n",
    "# intialize DataFrames\n",
    "first_level_predictions = pd.DataFrame()\n",
    "second_level_input = pd.DataFrame()\n",
    "\n",
    "# generate the first level predictions and second level input\n",
    "for key in first_level_keys:\n",
    "    first_level_predictions[key] = first_level_models[key].predict(x_train)\n",
    "    second_level_input[key] = first_level_models[key].predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Optional heatmap below to view the correlation of the different models' predictions.  It is good to have uncorrelated models in the blend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = plt.cm.viridis\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "sns.heatmap(first_level_predictions.astype(float).corr(),linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Blended model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC = GradientBoostingClassifier()\n",
    "\n",
    "# fit the first level predicitons\n",
    "GBC.fit(first_level_predictions, y_train)\n",
    "\n",
    "# generate second level prediction\n",
    "second_level_prediction = GBC.predict(second_level_input)\n",
    "\n",
    "print('Blended Model (GBC): ',round(accuracy_score(second_level_prediction, y_test) * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB = xgboost.XGBClassifier()\n",
    "\n",
    "# fit the first level predicitons\n",
    "XGB.fit(first_level_predictions, y_train)\n",
    "\n",
    "# generate second level prediction\n",
    "second_level_prediction = XGB.predict(second_level_input)\n",
    "\n",
    "print('Blended Model (XGB): ',round(accuracy_score(second_level_prediction, y_test) * 100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validation = validation_data.drop(target,axis=1)\n",
    "y_validation = validation_data[target]\n",
    "\n",
    "# intialize DataFrames\n",
    "first_level_predictions = pd.DataFrame()\n",
    "second_level_input = pd.DataFrame()\n",
    "\n",
    "# generate the first level predictions and second level input\n",
    "for key in first_level_keys:\n",
    "    second_level_input[key] = first_level_models[key].predict(x_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn Gradient Boosted Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_prediction = GBC.predict(second_level_input)\n",
    "print('Blended Model Validation: ',round(accuracy_score(validation_prediction, y_validation) * 100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_prediction = XGB.predict(second_level_input)\n",
    "print('Blended Model Validation: ',round(accuracy_score(validation_prediction, y_validation) * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
